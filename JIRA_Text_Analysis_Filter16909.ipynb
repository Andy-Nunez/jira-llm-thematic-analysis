{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0366071",
   "metadata": {},
   "source": [
    "# Jira Comments Analysis ‚Äì Sentiment & Themes\n",
    "\n",
    "This notebook loads Jira comments from a CSV file and walks through:\n",
    "\n",
    "1. **Loading & inspecting the data**\n",
    "2. **Cleaning / preprocessing the comment text**\n",
    "3. **Running sentiment analysis with a HuggingFace model**\n",
    "4. **Clustering comments into themes (reasons for delay) using TF‚ÄëIDF + KMeans**\n",
    "5. **Summarizing the top reasons issues weren‚Äôt completed**\n",
    "\n",
    "> üîß Before you start: update the `csv_path` variable in **Cell 2** so it points to your `JiraComments_FromJql.csv` file on your machine (e.g. `C:\\\\Users\\\\Andy\\\\Desktop\\\\JiraComments_FromJql.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baabe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 ‚Äì Imports and (optional) installs\n",
    "# Run this cell first.\n",
    "\n",
    "# If you don't have these installed yet, uncomment the pip commands below\n",
    "# (remove the leading '#') and run once.\n",
    "\n",
    "# !pip install pandas matplotlib scikit-learn transformers sentencepiece accelerate -q\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 ‚Äì Load CSV (update csv_path for your machine)\n",
    "\n",
    "# üëâ Change this to the actual path of your CSV file.\n",
    "# Example:\n",
    "# csv_path = r\"C:\\Users\\Andy\\Desktop\\JiraComments_FromJql.csv\"\n",
    "\n",
    "csv_path = r\"C:\\Users\\Andy\\Desktop\\Text Analysis\\JiraComments_FromJql.csv\"  # <-- update this line\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV not found at: {csv_path}\\nPlease update csv_path to the correct location.\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f7d36",
   "metadata": {},
   "source": [
    "## Basic cleaning & selection\n",
    "\n",
    "We keep the most relevant columns:\n",
    "\n",
    "- **IssueKey** ‚Äì which Jira issue the comment belongs to  \n",
    "- **Author** (if present) ‚Äì who wrote the comment  \n",
    "- **Created / Updated** ‚Äì timestamps  \n",
    "- **Body** ‚Äì the actual comment text\n",
    "\n",
    "We‚Äôll create a cleaned‚Äëup `text_clean` column for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 ‚Äì Select relevant columns and clean text\n",
    "\n",
    "# Try common column names; adjust if your CSV uses different ones\n",
    "possible_issue_cols = [\"IssueKey\", \"issueKey\", \"Key\", \"key\"]\n",
    "possible_body_cols = [\"Body\", \"body\", \"Comment\", \"comment\"]\n",
    "\n",
    "issue_col = next((c for c in possible_issue_cols if c in df.columns), None)\n",
    "body_col  = next((c for c in possible_body_cols  if c in df.columns), None)\n",
    "\n",
    "if issue_col is None or body_col is None:\n",
    "    raise ValueError(f\"Could not find issue or body column.\\n\"\n",
    "                     f\"Available columns: {list(df.columns)}\\n\"\n",
    "                     f\"Expected something like {possible_issue_cols} and {possible_body_cols}\")\n",
    "\n",
    "print(f\"Using issue column: {issue_col}\")\n",
    "print(f\"Using body column : {body_col}\")\n",
    "\n",
    "# Keep a working copy\n",
    "data = df[[issue_col, body_col]].copy()\n",
    "data.rename(columns={issue_col: \"IssueKey\", body_col: \"Body\"}, inplace=True)\n",
    "\n",
    "# Drop empty comments\n",
    "data[\"Body\"] = data[\"Body\"].astype(str).str.strip()\n",
    "data = data[data[\"Body\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(\"After dropping empty comments:\", len(data))\n",
    "\n",
    "# Simple text cleaning function\n",
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = str(text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    # Remove Jira-like markup (basic)\n",
    "    text = re.sub(r\"\\[~?\\w+\\]\", \" \", text)  # mentions\n",
    "    # Remove non-alphanumeric except basic punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s,.!?'-]\", \" \", text)\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "data[\"text_clean\"] = data[\"Body\"].apply(clean_text)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad50f9",
   "metadata": {},
   "source": [
    "## Sentiment analysis with HuggingFace\n",
    "\n",
    "We‚Äôll use a pretrained sentiment model from HuggingFace to label each comment as **positive** or **negative** (and a score).  \n",
    "Feel free to change the model name if you prefer another sentiment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61248fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 ‚Äì Setup HuggingFace sentiment pipeline\n",
    "\n",
    "# You can change this to another English sentiment model if you like\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=sentiment_model,\n",
    "    tokenizer=sentiment_tokenizer,\n",
    "    device=-1  # use CPU; set to 0 to use GPU if available\n",
    ")\n",
    "\n",
    "sentiment_pipe(\"This is a quick test to see if the model works.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 ‚Äì Run sentiment on all comments (batched)\n",
    "\n",
    "texts = data[\"text_clean\"].tolist()\n",
    "results = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    batch_results = sentiment_pipe(batch, truncation=True)\n",
    "    results.extend(batch_results)\n",
    "    print(f\"Processed {min(i+batch_size, len(texts))}/{len(texts)} comments\", end=\"\\r\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "\n",
    "data[\"sentiment_label\"] = [r[\"label\"] for r in results]\n",
    "data[\"sentiment_score\"] = [r[\"score\"] for r in results]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 ‚Äì Sentiment summary\n",
    "\n",
    "print(data[\"sentiment_label\"].value_counts())\n",
    "\n",
    "# Plot distribution\n",
    "data[\"sentiment_label\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment label distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Average score by label\n",
    "data.groupby(\"sentiment_label\")[\"sentiment_score\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f2f27",
   "metadata": {},
   "source": [
    "## Thematic analysis (reasons / topics)\n",
    "\n",
    "We‚Äôll use a simple unsupervised approach:\n",
    "\n",
    "1. Convert comments into TF‚ÄëIDF vectors.  \n",
    "2. Cluster them using KMeans.  \n",
    "3. Inspect the **top terms per cluster** and some **example comments** to interpret themes.\n",
    "\n",
    "You can adjust the number of clusters (`n_clusters`) depending on how fine‚Äëgrained you want the themes to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbaa0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 ‚Äì TF-IDF vectorization\n",
    "\n",
    "# You can tweak max_features or stop_words if needed\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(data[\"text_clean\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2c146-8ede-4f68-ae9a-35e7a9c35e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threadpoolctl\n",
    "\n",
    "class _NoOpThreadpoolLimit:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "\n",
    "# Monkey-patch threadpoolctl so scikit-learn's KMeans doesn't try\n",
    "# to introspect BLAS libraries (which is what's crashing on Windows).\n",
    "threadpoolctl.threadpool_limits = _NoOpThreadpoolLimit\n",
    "\n",
    "print(\"Patched threadpoolctl.threadpool_limits ‚Äì KMeans should work now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 ‚Äì KMeans clustering into themes\n",
    "\n",
    "n_clusters = 6  # adjust this number as needed\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    random_state=42,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "data[\"cluster\"] = cluster_labels\n",
    "\n",
    "data[\"cluster\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 ‚Äì Inspect top terms per cluster\n",
    "\n",
    "def print_top_terms_per_cluster(kmeans_model, vectorizer, n_terms=15):\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    order_centroids = kmeans_model.cluster_centers_.argsort()[:, ::-1]\n",
    "    for i in range(kmeans_model.n_clusters):\n",
    "        top_terms = terms[order_centroids[i, :n_terms]]\n",
    "        print(f\"\\nCluster {i} ‚Äì top terms:\")\n",
    "        print(\", \".join(top_terms))\n",
    "\n",
    "print_top_terms_per_cluster(kmeans, vectorizer, n_terms=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6760204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 ‚Äì Example comments per cluster\n",
    "\n",
    "for c in range(n_clusters):\n",
    "    print(f\"\\n==================== Cluster {c} ====================\")\n",
    "    cluster_subset = data[data[\"cluster\"] == c].head(5)  # show up to 5 examples\n",
    "    for _, row in cluster_subset.iterrows():\n",
    "        print(f\"[{row['IssueKey']}] ({row['sentiment_label']}, {row['sentiment_score']:.2f})\")\n",
    "        print(row[\"Body\"][:500])\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c75055",
   "metadata": {},
   "source": [
    "## Putting it together: top themes & blocker-style comments\n",
    "\n",
    "At this point you can:\n",
    "\n",
    "- Manually label each cluster with a **theme name** (e.g., ‚ÄúWaiting on other team‚Äù, ‚ÄúTesting issues‚Äù, ‚ÄúRequirements unclear‚Äù).  \n",
    "- Filter for **negative** comments within each cluster to see which themes are associated with delays or frustration.  \n",
    "- Export the enriched dataset back to CSV for reporting or dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 ‚Äì Example: negative comments by cluster\n",
    "\n",
    "neg = data[data[\"sentiment_label\"] == \"NEGATIVE\"]\n",
    "\n",
    "summary = neg.groupby(\"cluster\").agg(\n",
    "    n_comments=(\"Body\", \"count\")\n",
    ").reset_index().sort_values(\"n_comments\", ascending=False)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca883b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 ‚Äì Export enriched data (optional)\n",
    "\n",
    "output_path = os.path.splitext(csv_path)[0] + \"_enriched_with_sentiment_clusters.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Saved enriched data to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
