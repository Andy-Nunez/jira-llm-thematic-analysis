{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIRA Delay Analysis - October to November\n",
    "\n",
    "**Goal**: Identify top 5 and top 10 themes causing delays from October to November using LLM-assisted sentiment analysis\n",
    "\n",
    "**Approach**:\n",
    "1. Load and clean JIRA data\n",
    "2. Filter October issues delayed to November\n",
    "3. Extract and analyze comments using GPT\n",
    "4. Cluster themes and identify root causes\n",
    "5. Generate actionable management insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for custom modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✅ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JIRA CSV data\n",
    "# Update the filename to match your actual JIRA export\n",
    "data_path = '../data/raw/jira_export.csv'\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"⚠️ File not found: {data_path}\")\n",
    "    print(\"Please place your JIRA CSV export in the data/raw/ directory\")\n",
    "else:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"✅ Loaded {len(df)} records\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check\n",
    "print(\"Data Quality Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "# Adjust column names based on your actual JIRA export\n",
    "date_columns = ['Created', 'Updated', 'Resolved']  # Update these column names\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "print(\"✅ Date columns converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for October issues delayed to November\n",
    "# Define October and November date ranges\n",
    "october_start = pd.Timestamp('2024-10-01')\n",
    "october_end = pd.Timestamp('2024-10-31')\n",
    "november_start = pd.Timestamp('2024-11-01')\n",
    "november_end = pd.Timestamp('2024-11-30')\n",
    "\n",
    "# Filter logic: Created in October, Resolved in November (or still open)\n",
    "# Adjust column names to match your data\n",
    "delayed_issues = df[\n",
    "    (df['Created'] >= october_start) & \n",
    "    (df['Created'] <= october_end) &\n",
    "    (\n",
    "        (df['Resolved'] >= november_start) |\n",
    "        (df['Resolved'].isnull())\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(f\"✅ Found {len(delayed_issues)} delayed issues\")\n",
    "delayed_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comment Extraction and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract comments from delayed issues\n",
    "# Adjust 'Comment' column name to match your data\n",
    "comment_column = 'Comment'  # Or 'Comments', 'Description', etc.\n",
    "\n",
    "if comment_column in delayed_issues.columns:\n",
    "    # Remove null comments\n",
    "    issues_with_comments = delayed_issues[delayed_issues[comment_column].notna()].copy()\n",
    "    print(f\"✅ {len(issues_with_comments)} issues have comments\")\n",
    "    \n",
    "    # Sample of comments\n",
    "    print(\"\\nSample comments:\")\n",
    "    for idx, comment in issues_with_comments[comment_column].head(3).items():\n",
    "        print(f\"\\n--- Issue {idx} ---\")\n",
    "        print(comment[:200] + \"...\" if len(str(comment)) > 200 else comment)\n",
    "else:\n",
    "    print(f\"⚠️ Column '{comment_column}' not found. Available columns: {list(delayed_issues.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM-Assisted Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom LLM analyzer\n",
    "from llm_analyzer import DelayThemeAnalyzer\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = DelayThemeAnalyzer()\n",
    "\n",
    "print(\"✅ LLM analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze comments for delay themes\n",
    "# This will make API calls to OpenAI - monitor your usage\n",
    "\n",
    "delay_themes = []\n",
    "\n",
    "for idx, row in tqdm(issues_with_comments.iterrows(), total=len(issues_with_comments), desc=\"Analyzing comments\"):\n",
    "    issue_key = row.get('Key', idx)\n",
    "    comment_text = row[comment_column]\n",
    "    \n",
    "    # Get delay theme from GPT\n",
    "    theme_result = analyzer.extract_delay_theme(comment_text, issue_key)\n",
    "    delay_themes.append(theme_result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "themes_df = pd.DataFrame(delay_themes)\n",
    "print(f\"\\n✅ Analyzed {len(themes_df)} issues\")\n",
    "themes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Theme Clustering and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count theme frequencies\n",
    "theme_counts = themes_df['theme'].value_counts()\n",
    "\n",
    "print(\"Top 10 Delay Themes:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (theme, count) in enumerate(theme_counts.head(10).items(), 1):\n",
    "    percentage = (count / len(themes_df)) * 100\n",
    "    print(f\"{i}. {theme}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 themes\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_10_themes = theme_counts.head(10)\n",
    "sns.barplot(x=top_10_themes.values, y=top_10_themes.index, palette='viridis')\n",
    "plt.xlabel('Number of Issues', fontsize=12)\n",
    "plt.ylabel('Delay Theme', fontsize=12)\n",
    "plt.title('Top 10 Delay Themes - October to November', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/top_10_delay_themes.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Saved visualization to reports/top_10_delay_themes.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment distribution\n",
    "if 'sentiment' in themes_df.columns:\n",
    "    sentiment_counts = themes_df['sentiment'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = {'negative': '#e74c3c', 'neutral': '#95a5a6', 'positive': '#2ecc71'}\n",
    "    sentiment_counts.plot(kind='bar', color=[colors.get(x, '#3498db') for x in sentiment_counts.index])\n",
    "    plt.xlabel('Sentiment', fontsize=12)\n",
    "    plt.ylabel('Number of Issues', fontsize=12)\n",
    "    plt.title('Sentiment Distribution in Delayed Issues', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/sentiment_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Actionable Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actionable recommendations\n",
    "top_5_themes = theme_counts.head(5)\n",
    "top_10_themes = theme_counts.head(10)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ACTIONABLE MANAGEMENT INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAnalysis Period: October 2024 → November 2024\")\n",
    "print(f\"Total Delayed Issues: {len(delayed_issues)}\")\n",
    "print(f\"Issues with Comments: {len(issues_with_comments)}\")\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "print(\"TOP 5 CRITICAL DELAY THEMES:\")\n",
    "print(\"-\"*70)\n",
    "for i, (theme, count) in enumerate(top_5_themes.items(), 1):\n",
    "    percentage = (count / len(themes_df)) * 100\n",
    "    print(f\"\\n{i}. {theme.upper()}\")\n",
    "    print(f\"   Impact: {count} issues ({percentage:.1f}%)\")\n",
    "    print(f\"   Recommendation: [Add specific action based on theme]\")\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "print(\"FULL TOP 10 THEMES FOR COMPREHENSIVE PLANNING:\")\n",
    "print(\"-\"*70)\n",
    "for i, (theme, count) in enumerate(top_10_themes.items(), 1):\n",
    "    percentage = (count / len(themes_df)) * 100\n",
    "    print(f\"{i}. {theme}: {count} issues ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export theme analysis to CSV\n",
    "themes_df.to_csv('../data/processed/delay_themes_analysis.csv', index=False)\n",
    "print(\"✅ Saved detailed analysis to data/processed/delay_themes_analysis.csv\")\n",
    "\n",
    "# Export top themes summary\n",
    "top_themes_summary = pd.DataFrame({\n",
    "    'Rank': range(1, 11),\n",
    "    'Theme': top_10_themes.index,\n",
    "    'Count': top_10_themes.values,\n",
    "    'Percentage': (top_10_themes.values / len(themes_df) * 100).round(1)\n",
    "})\n",
    "\n",
    "top_themes_summary.to_csv('../reports/top_10_themes_summary.csv', index=False)\n",
    "print(\"✅ Saved top 10 summary to reports/top_10_themes_summary.csv\")\n",
    "\n",
    "# Export top 5 for management\n",
    "top_5_summary = top_themes_summary.head(5)\n",
    "top_5_summary.to_csv('../reports/top_5_critical_themes.csv', index=False)\n",
    "print(\"✅ Saved top 5 critical themes to reports/top_5_critical_themes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "### Immediate Actions:\n",
    "1. Review top 5 themes with team leads\n",
    "2. Assign owners to each critical theme\n",
    "3. Create improvement initiatives based on findings\n",
    "4. Set KPIs to track improvement in next sprint\n",
    "\n",
    "### Continuous Improvement:\n",
    "- Run this analysis monthly to track trends\n",
    "- Compare month-over-month theme changes\n",
    "- Measure effectiveness of interventions\n",
    "- Adjust team processes based on data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
